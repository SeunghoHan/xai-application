{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a378122-24e9-493a-b10b-99b2045f871f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sns\n",
    "# from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "\n",
    "from data.data_loader import EPCDataset, PowerWeatherDatasetWithSeason, PowerWeatherDataset, SingleTermDataset, MultiTermDataset\n",
    "from models.lstm import LSTMModel\n",
    "from models.lstm_attention import LSTMWithAttention, BiLSTMWithAttention\n",
    "from models.gru import GRUModel\n",
    "from models.utils import create_model, train_for_short_term_forecast, train_for_long_term_forecast, load_model, evaluate_for_short_term_forecast, evaluate_for_long_term_forecast\n",
    "\n",
    "from explainers.utils import get_explainer\n",
    "# from explainers.lime import LimeExplainer\n",
    "# from explainers.shap import ShapExplainer\n",
    "# from explainers.attention import AttentionExplainer\n",
    "# from explainers.grad_cam import GradCAMExplainer\n",
    "# from explainers.lrp import LRPExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2bc625c-277b-44f9-aa90-811371b463f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7feee264-26a5-4c8f-a1de-c814de4f08c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# short term \n",
    "features_for_1h = [\n",
    "    'Global_active_power',\n",
    "    'Global_intensity',\n",
    "    'Sub_metering_1', \n",
    "    'Sub_metering_2', \n",
    "    'Sub_metering_3', \n",
    "    'Temperature',\t\n",
    "    'Humidity',\t\n",
    "]\n",
    "\n",
    "# long term\n",
    "features_for_6h = [\n",
    "    'Global_active_power',\n",
    "    'Global_intensity',\n",
    "    'Sub_metering_1', \n",
    "    'Sub_metering_2', \n",
    "    'Sub_metering_3', \n",
    "    'Temp_Min',\t'Temp_Max', 'Temp_Avg',\t'Temp_Range',\n",
    "    'Humidity_Min',\t'Humidity_Max',\t'Humidity_Avg',\t'Humidity_Range'\n",
    "]\n",
    "\n",
    "file_path_for_1h = 'data/final_data.csv'\n",
    "file_path_for_6h = 'data/final_data_per_6hr_with_avg_range.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4bcbe292-9aa1-471f-a2bd-e5e2ea17e1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(params, target_features_long, target_features_short, is_long_term_forecast=True):\n",
    "    selected_features = dict()\n",
    "    \n",
    "    if is_long_term_forecast:\n",
    "        dataset_6h = EPCDataset(\n",
    "            # file_path=file_path_for_6h,\n",
    "            file_path=file_path_for_1h,\n",
    "            sequence_length=params['long_term_length'],  \n",
    "            prediction_length=params['long_term_pred_length'],\n",
    "            target_features=target_features_long\n",
    "        )\n",
    "        train_long, train_targets_long, eval_long, eval_targets_long = dataset_6h.load_data()\n",
    "        \n",
    "        dataset_1h = EPCDataset(\n",
    "            file_path=file_path_for_1h,\n",
    "            sequence_length=params['short_term_length'],  \n",
    "            prediction_length=params['short_term_pred_length'],\n",
    "            target_features=target_features_short\n",
    "        )\n",
    "        train_short, train_targets_short, eval_short, eval_targets_short = dataset_1h.load_data()\n",
    "        \n",
    "        train_data=(train_long, train_short)\n",
    "        train_targets=(train_targets_long, train_targets_short)\n",
    "        eval_data=(eval_long, eval_short)\n",
    "        eval_targets=(eval_targets_long, eval_targets_short)\n",
    "\n",
    "        selected_features['long'] = dataset_6h.selected_features\n",
    "        selected_features['short'] = dataset_1h.selected_features\n",
    "\n",
    "    else:\n",
    "        dataset_1h = EPCDataset(\n",
    "            file_path=file_path_for_1h,\n",
    "            sequence_length=params['sequence_length'],  \n",
    "            prediction_length=params['prediction_length'],\n",
    "            target_features=target_features_short\n",
    "        )\n",
    "        \n",
    "        train_sequence, train_targets_sequence, eval_sequence, eval_targets_sequence = dataset_1h.load_data()\n",
    "\n",
    "        train_data=train_sequence\n",
    "        train_targets=train_targets_sequence\n",
    "        eval_data=eval_sequence\n",
    "        eval_targets=eval_targets_sequence\n",
    "    \n",
    "        selected_features['single'] = dataset_1h.selected_features\n",
    "\n",
    "    return train_data, train_targets, eval_data, eval_targets, selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d65abf8-0e5c-4c87-a567-a04bf5e5a47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task\n",
    "## long-term forecast: 일주일 전력량 예측 (7*24) -> Long-term Short-term CNN-LSTM 모델\n",
    "## Short-term forecast: 하루 전력량 예측 (24)    -> LSTM, GRU, CNN-LSTM 모델 \n",
    "\n",
    "# 1. 온/습도 정보 없는 케이스도 비교 필요 \n",
    "\n",
    "\n",
    "dataset_params = {\n",
    "    # for long-term forecast \n",
    "\n",
    "    # 'long_term_length' : 365*4, # 6시간 단위 1년 데이터\n",
    "    'long_term_length' : 90*24,\n",
    "    'long_term_pred_length' : 256, # 64, 128, 256\n",
    "    \n",
    "    'short_term_length' : 30*24, # 1시간 단위 한달 데이터\n",
    "    'short_term_pred_length' : 7*24, # 일주일 데이터 예측\n",
    "\n",
    "    \n",
    "    # 2. LSTM, GRU, CNN-LSTM  -> 365*24 / 7*24 (비교용)\n",
    "    # for Short-term forecast \n",
    "    'sequence_length' : 24*30,  # -> 일주일 / 10일 / 15일 / 한달  \n",
    "    'prediction_length' : 24\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff562da6-d00e-4193-8c73-1e7c14b5a480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6-hour data sequences for long-term forecast:\n",
      "  Train sequences shape: torch.Size([22588, 2160, 13])\n",
      "  Train targets shape: torch.Size([22588, 256])\n",
      "  Eval sequences shape: torch.Size([5647, 2160, 13])\n",
      "  Eval targets shape: torch.Size([5647, 256])\n",
      "  Selected_features: ['Global_active_power', 'Global_intensity', 'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3', 'Temperature', 'Humidity', 'sin_hour', 'cos_hour', 'sin_day', 'cos_day', 'sin_month', 'cos_month']\n",
      "\n",
      "1-hour data sequences for long-term forecast:\n",
      "  Train sequences shape: torch.Size([23810, 720, 13])\n",
      "  Train targets shape: torch.Size([23810, 168])\n",
      "  Eval sequences shape: torch.Size([5953, 720, 13])\n",
      "  Eval targets shape: torch.Size([5953, 168])\n",
      "  Selected_features: ['Global_active_power', 'Global_intensity', 'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3', 'Temperature', 'Humidity', 'sin_hour', 'cos_hour', 'sin_day', 'cos_day', 'sin_month', 'cos_month']\n"
     ]
    }
   ],
   "source": [
    "is_long_term_forecast = True\n",
    "\n",
    "train_data, train_targets, eval_data, eval_targets, selected_features = load_dataset(params=dataset_params,\n",
    "                                                                                     target_features_long=features_for_1h, \n",
    "                                                                                     target_features_short=features_for_1h, \n",
    "                                                                                     is_long_term_forecast=True)\n",
    "if isinstance(train_data, tuple):\n",
    "    print(\"6-hour data sequences for long-term forecast:\")\n",
    "    print(f\"  Train sequences shape: {train_data[0].shape}\")\n",
    "    print(f\"  Train targets shape: {train_targets[0].shape}\")\n",
    "    print(f\"  Eval sequences shape: {eval_data[0].shape}\")\n",
    "    print(f\"  Eval targets shape: {eval_targets[0].shape}\")\n",
    "    print(f\"  Selected_features: {selected_features['long']}\")\n",
    "    \n",
    "    print(\"\\n1-hour data sequences for long-term forecast:\")\n",
    "    print(f\"  Train sequences shape: {train_data[1].shape}\")\n",
    "    print(f\"  Train targets shape: {train_targets[1].shape}\")\n",
    "    print(f\"  Eval sequences shape: {eval_data[1].shape}\")\n",
    "    print(f\"  Eval targets shape: {eval_targets[1].shape}\")\n",
    "    print(f\"  Selected_features: {selected_features['short']}\")\n",
    "    \n",
    "else:\n",
    "    print(\"1-hour data sequences for short-term forecast:\")\n",
    "    print(f\"  Train sequences shape: {train_data.shape}\")\n",
    "    print(f\"  Train targets shape: {train_targets.shape}\")\n",
    "    print(f\"  Eval sequences shape: {eval_data.shape}\")\n",
    "    print(f\"  Eval targets shape: {eval_targets.shape}\")\n",
    "    print(f\"  Selected_features: {selected_features['single']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7fda2d3-4bd9-4943-af03-10519027718b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_model(params):\n",
    "    if params is None:\n",
    "        return\n",
    "\n",
    "    # Extract parameters\n",
    "    model_name = params['model_name']\n",
    "    hidden_size = params['hidden_size']\n",
    "    num_layers = params['num_layers']\n",
    "    dropout = params['dropout']\n",
    "    num_epochs = params['num_epochs']\n",
    "    batch_size = params['batch_size']\n",
    "    learning_rate = params['learning_rate']\n",
    "    patience = params['patience']\n",
    "    mse_decay = params['mse_decay']\n",
    "\n",
    "    # Determine input size and output size\n",
    "    input_size = {\n",
    "        # 'long': len(features_for_6h)+6,\n",
    "        'long': len(features_for_1h)+6,\n",
    "        'short': len(features_for_1h)+6,\n",
    "        'single': len(features_for_1h)+6\n",
    "    }\n",
    "    output_size = {\n",
    "        'long': dataset_params['long_term_pred_length'],\n",
    "        'short': dataset_params['short_term_pred_length'],\n",
    "        'single': dataset_params['prediction_length']\n",
    "    }\n",
    "\n",
    "    if mse_decay:\n",
    "        mse_alpha = 0.3\n",
    "        mse_beta = 1.0\n",
    "\n",
    "    else:\n",
    "        mse_alpha = 1.0\n",
    "        mse_beta = 1.0\n",
    "\n",
    "    # Model 생성 \n",
    "    model = create_model(\n",
    "        model_name=model_name,\n",
    "        input_size=input_size,\n",
    "        hidden_size=hidden_size,\n",
    "        num_layers=num_layers,\n",
    "        output_size=output_size,\n",
    "        dropout=dropout, \n",
    "        long_term_length=dataset_params['long_term_length'], \n",
    "        short_term_length=dataset_params['short_term_length']\n",
    "    ) \n",
    "\n",
    "    if 'LS_CNNLSTM' in model_name:\n",
    "        model_path = './trained_models/{}_long_{}_short_{}_{}_{}_{}_alpha_{}_beta_{}.pth'.format(\n",
    "            model_name, dataset_params['long_term_length'], dataset_params['short_term_length'],\n",
    "            dataset_params['long_term_pred_length'], hidden_size, num_layers, mse_alpha, mse_beta\n",
    "        )\n",
    "    else:\n",
    "        model_path = './trained_models/{}_{}_{}.pth'.format(\n",
    "            model_name, dataset_params['sequence_length'], dataset_params['prediction_length']\n",
    "        )\n",
    "        \n",
    "    print(\"Model path:\", model_path)\n",
    "\n",
    "    # Load pre-trained model or train a new one\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"Loading the pre-trained {model_name} model...\")\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        model.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "    else:\n",
    "        print(f\"{model_name} model not found. Training a new model...\")\n",
    "        if 'LS_CNNLSTM' in model_name:\n",
    "            train_for_long_term_forecast(\n",
    "                model=model,\n",
    "                model_name=model_name,\n",
    "                train_data=train_data,\n",
    "                train_targets=train_targets,\n",
    "                eval_data=eval_data,\n",
    "                eval_targets=eval_targets,\n",
    "                model_path=model_path,\n",
    "                num_epochs=num_epochs,\n",
    "                batch_size=batch_size,\n",
    "                learning_rate=learning_rate,\n",
    "                patience=patience,\n",
    "                oversample_eval=True, \n",
    "                alpha=mse_alpha, \n",
    "                beta=mse_beta\n",
    "            )\n",
    "        else:\n",
    "            train_for_short_term_forecast(\n",
    "                model=model,\n",
    "                model_name=model_name,\n",
    "                train_sequences=train_data,\n",
    "                train_targets=train_targets,\n",
    "                eval_sequences=eval_data,\n",
    "                eval_targets=eval_targets,\n",
    "                model_path=model_path,\n",
    "                num_epochs=num_epochs,\n",
    "                batch_size=batch_size,\n",
    "                learning_rate=learning_rate,\n",
    "                patience=patience\n",
    "            )\n",
    "\n",
    "    return model, model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99aa0bae-7d79-4a93-b3e2-bf09e17070dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10d4424a-b306-42d8-89b1-9a906fa15cb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path: ./trained_models/LS_CNNLSTM_long_2160_short_720_256_256_3_alpha_0.3_beta_1.0.pth\n",
      "Loading the pre-trained LS_CNNLSTM model...\n",
      "Evaluating the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20448/3867406579.py:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score: 0.8597\n",
      "Adjusted R²: 0.8594\n",
      "SMAPE: 33.18\n",
      "MASE: 0.5526\n",
      "Model path: ./trained_models/LS_CNNLSTM_long_2160_short_720_256_256_3_alpha_1.0_beta_1.0.pth\n",
      "Loading the pre-trained LS_CNNLSTM model...\n",
      "Evaluating the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20448/3867406579.py:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score: 0.8486\n",
      "Adjusted R²: 0.8483\n",
      "SMAPE: 33.69\n",
      "MASE: 0.5715\n",
      "Model path: ./trained_models/LS_CNNLSTM_long_2160_short_720_256_512_3_alpha_0.3_beta_1.0.pth\n",
      "Loading the pre-trained LS_CNNLSTM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20448/3867406579.py:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model...\n",
      "R² Score: 0.8329\n",
      "Adjusted R²: 0.8326\n",
      "SMAPE: 33.99\n",
      "MASE: 0.5964\n",
      "Model path: ./trained_models/LS_CNNLSTM_long_2160_short_720_256_512_3_alpha_1.0_beta_1.0.pth\n",
      "Loading the pre-trained LS_CNNLSTM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20448/3867406579.py:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model...\n",
      "R² Score: 0.8353\n",
      "Adjusted R²: 0.8349\n",
      "SMAPE: 34.89\n",
      "MASE: 0.5958\n",
      "Model path: ./trained_models/LS_CNNLSTM_Att_long_2160_short_720_256_256_3_alpha_0.3_beta_1.0.pth\n",
      "Loading the pre-trained LS_CNNLSTM_Att model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20448/3867406579.py:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model...\n",
      "R² Score: 0.7264\n",
      "Adjusted R²: 0.7258\n",
      "SMAPE: 39.99\n",
      "MASE: 0.7689\n",
      "Model path: ./trained_models/LS_CNNLSTM_Att_long_2160_short_720_256_256_3_alpha_1.0_beta_1.0.pth\n",
      "Loading the pre-trained LS_CNNLSTM_Att model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20448/3867406579.py:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model...\n",
      "R² Score: 0.7085\n",
      "Adjusted R²: 0.7079\n",
      "SMAPE: 41.08\n",
      "MASE: 0.7915\n",
      "Model path: ./trained_models/LS_CNNLSTM_Att_long_2160_short_720_256_512_3_alpha_0.3_beta_1.0.pth\n",
      "Loading the pre-trained LS_CNNLSTM_Att model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20448/3867406579.py:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model...\n",
      "R² Score: 0.7782\n",
      "Adjusted R²: 0.7777\n",
      "SMAPE: 38.92\n",
      "MASE: 0.6968\n",
      "Model path: ./trained_models/LS_CNNLSTM_Att_long_2160_short_720_256_512_3_alpha_1.0_beta_1.0.pth\n",
      "Loading the pre-trained LS_CNNLSTM_Att model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20448/3867406579.py:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model...\n",
      "R² Score: 0.8145\n",
      "Adjusted R²: 0.8141\n",
      "SMAPE: 37.51\n",
      "MASE: 0.6376\n"
     ]
    }
   ],
   "source": [
    "model_names = ['LS_CNNLSTM', 'LS_CNNLSTM_Att']\n",
    "hidden_sizes = [256, 512]\n",
    "mse_decayes = [True, False]\n",
    "\n",
    "# results_for_compare = {}\n",
    "original_results = {} \n",
    "\n",
    "# itertools.product를 사용하여 모든 조합 생성\n",
    "for model_name, hidden_size, mse_decay in product(model_names, hidden_sizes, mse_decayes):\n",
    "    # print(f\"Model: {model_name}, Hidden Size: {hidden_size}, MSE Decay: {mse_decay}\")\n",
    "   \n",
    "    model_params = {\n",
    "        'model_name' : model_name, \n",
    "        'hidden_size' : hidden_size,\n",
    "        'num_layers' : 3, \n",
    "        'dropout' : 0.3,\n",
    "        'num_epochs' : 200,\n",
    "        'batch_size' : 16,\n",
    "        'learning_rate' : 0.001,\n",
    "        'patience' : 12,\n",
    "        'mse_decay' : mse_decay\n",
    "    }\n",
    "\n",
    "    model, model_path = load_trained_model(model_params)\n",
    "\n",
    "    \n",
    "    print(\"Evaluating the model...\")\n",
    "    if is_long_term_forecast:\n",
    "        results = evaluate_for_long_term_forecast(\n",
    "            model=model,\n",
    "            eval_data=eval_data,\n",
    "            eval_targets=eval_targets,\n",
    "            model_name=model_params['model_name'],\n",
    "            batch_size=model_params['batch_size'], \n",
    "            oversample_eval=True \n",
    "        )\n",
    "    else:\n",
    "        results = evaluate_for_short_term_forecast(\n",
    "            model=model,\n",
    "            eval_sequences=eval_short,\n",
    "            eval_targets=eval_targets_short,\n",
    "            model_name=model_params['model_name'],\n",
    "            batch_size=model_params['batch_size']\n",
    "        )\n",
    "\n",
    "    key = '{}_{}_{}'.format(model_name, hidden_size, mse_decay)\n",
    "    original_results[key] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b497006d-6102-4356-8b25-46b0291da6b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LS_CNNLSTM_256_True': {'R2 Short': 0.8596751093864441,\n",
       "  'Adjusted R2': 0.8593679493295362,\n",
       "  'SMAPE Short': np.float32(33.17787),\n",
       "  'MASE Short': np.float32(0.55263716)},\n",
       " 'LS_CNNLSTM_256_False': {'R2 Short': 0.8486469984054565,\n",
       "  'Adjusted R2': 0.8483156986882097,\n",
       "  'SMAPE Short': np.float32(33.692307),\n",
       "  'MASE Short': np.float32(0.57151854)},\n",
       " 'LS_CNNLSTM_512_True': {'R2 Short': 0.8329382538795471,\n",
       "  'Adjusted R2': 0.8325725689663351,\n",
       "  'SMAPE Short': np.float32(33.991646),\n",
       "  'MASE Short': np.float32(0.5963537)},\n",
       " 'LS_CNNLSTM_512_False': {'R2 Short': 0.8353075981140137,\n",
       "  'Adjusted R2': 0.8349470995074271,\n",
       "  'SMAPE Short': np.float32(34.891926),\n",
       "  'MASE Short': np.float32(0.59581584)},\n",
       " 'LS_CNNLSTM_Att_256_True': {'R2 Short': 0.7264457941055298,\n",
       "  'Adjusted R2': 0.7258470056433934,\n",
       "  'SMAPE Short': np.float32(39.98949),\n",
       "  'MASE Short': np.float32(0.7689069)},\n",
       " 'LS_CNNLSTM_Att_256_False': {'R2 Short': 0.7085404396057129,\n",
       "  'Adjusted R2': 0.7079024577425834,\n",
       "  'SMAPE Short': np.float32(41.084106),\n",
       "  'MASE Short': np.float32(0.79151314)},\n",
       " 'LS_CNNLSTM_Att_512_True': {'R2 Short': 0.7781588435173035,\n",
       "  'Adjusted R2': 0.7776732508191598,\n",
       "  'SMAPE Short': np.float32(38.9189),\n",
       "  'MASE Short': np.float32(0.69680655)},\n",
       " 'LS_CNNLSTM_Att_512_False': {'R2 Short': 0.8145430684089661,\n",
       "  'Adjusted R2': 0.8141371178936128,\n",
       "  'SMAPE Short': np.float32(37.50649),\n",
       "  'MASE Short': np.float32(0.6376317)}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff217966-e321-4fe2-ae71-9e66d236623f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d30a64-54f1-45a8-a1a9-4af9ebc639e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d12512e-38ea-4e27-b7c3-f45de3b50c86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59a047b5-c2e1-464c-90bd-eb80a656bdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "# 파일 경로\n",
    "file_path = \"important_features_top5.txt\"\n",
    "\n",
    "# 저장할 딕셔너리\n",
    "important_features_dict = {}\n",
    "\n",
    "# 정규 표현식 패턴\n",
    "model_path_pattern = re.compile(r\"\\./trained_models/(.+)\")\n",
    "feature_pattern = re.compile(r\"([\\w_]+): ([\\d\\.]+)\")\n",
    "\n",
    "features = [\n",
    "    'Global_active_power',\n",
    "    'Global_intensity',\n",
    "    'Sub_metering_1', \n",
    "    'Sub_metering_2', \n",
    "    'Sub_metering_3', \n",
    "    'Temperature',    \n",
    "    'Humidity',    \n",
    "]\n",
    "\n",
    "\n",
    "# 변수 초기화\n",
    "current_model = None\n",
    "current_section = None\n",
    "\n",
    "# 파일 읽기\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        \n",
    "        # 모델 경로 감지 및 모델 키 추출\n",
    "        match = model_path_pattern.match(line)\n",
    "        if match:\n",
    "            current_model = match.group(1)\n",
    "            important_features_dict[current_model] = {\"Important Long-term Features\": {}, \"Important Short-term Features\": {}}\n",
    "            continue\n",
    "\n",
    "        # 섹션 감지\n",
    "        if \"Important Long-term Features\" in line:\n",
    "            current_section = \"Important Long-term Features\"\n",
    "            continue\n",
    "        elif \"Important Short-term Features\" in line:\n",
    "            current_section = \"Important Short-term Features\"\n",
    "            continue\n",
    "        \n",
    "        # Feature 값 추출\n",
    "        match = feature_pattern.match(line)\n",
    "        if match and current_model and current_section:\n",
    "            feature_name, score = match.groups()\n",
    "            if feature_name in features:\n",
    "                important_features_dict[current_model][current_section][feature_name] = float(score)\n",
    "\n",
    "# important_features_dict\n",
    "\n",
    "\n",
    "# for key, important_features in important_features_dict.items():\n",
    "\n",
    "#     # # print(important_features)\n",
    "#     # model_name = key.split('_long')[0]\n",
    "#     # hidden_size = 512 if '512' in key else 256\n",
    "#     # mse_decay = True if '0.3' in key else False\n",
    "\n",
    "#     important_features_for_long = []\n",
    "#     important_features_for_short = []\n",
    "    \n",
    "#     for feature_long in important_features['Important Long-term Features']:\n",
    "#         important_features_for_long.append(feature_long)\n",
    "    \n",
    "#     for feature_short in important_features['Important Short-term Features']:\n",
    "#         important_features_for_short.append(feature_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2c0d2cd-8ec3-47a9-9460-04660cc2db74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Global_active_power',\n",
       " 'Global_intensity',\n",
       " 'Sub_metering_2',\n",
       " 'Sub_metering_3',\n",
       " 'Humidity']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_features_for_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3f471a3-8e93-4aba-ad2b-4e9d7a2fd780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_new_features(params, is_long_term_forecast=True):\n",
    "    selected_features = dict()\n",
    "    \n",
    "    if is_long_term_forecast:\n",
    "        dataset_6h = EPCDataset(\n",
    "            file_path=file_path_for_1h,\n",
    "            sequence_length=params['long_term_length'],  \n",
    "            prediction_length=params['long_term_pred_length'],\n",
    "            target_features=important_features_for_long\n",
    "        )\n",
    "        train_long, train_targets_long, eval_long, eval_targets_long = dataset_6h.load_data()\n",
    "        \n",
    "        dataset_1h = EPCDataset(\n",
    "            file_path=file_path_for_1h,\n",
    "            sequence_length=params['short_term_length'],  \n",
    "            prediction_length=params['short_term_pred_length'],\n",
    "            target_features=important_features_for_short\n",
    "        )\n",
    "        train_short, train_targets_short, eval_short, eval_targets_short = dataset_1h.load_data()\n",
    "        \n",
    "        train_data=(train_long, train_short)\n",
    "        train_targets=(train_targets_long, train_targets_short)\n",
    "        eval_data=(eval_long, eval_short)\n",
    "        eval_targets=(eval_targets_long, eval_targets_short)\n",
    "\n",
    "        selected_features['long'] = dataset_6h.selected_features\n",
    "        selected_features['short'] = dataset_1h.selected_features\n",
    "\n",
    "    else:\n",
    "        dataset_1h = EPCDataset(\n",
    "            file_path=file_path_for_1h,\n",
    "            sequence_length=params['sequence_length'],  \n",
    "            prediction_length=params['prediction_length'],\n",
    "            target_features=important_features_for_1h\n",
    "        )\n",
    "        \n",
    "        train_sequence, train_targets_sequence, eval_sequence, eval_targets_sequence = dataset_1h.load_data()\n",
    "\n",
    "        train_data=train_sequence\n",
    "        train_targets=train_targets_sequence\n",
    "        eval_data=eval_sequence\n",
    "        eval_targets=eval_targets_sequence\n",
    "    \n",
    "        selected_features['single'] = dataset_1h.selected_features\n",
    "\n",
    "    return train_data, train_targets, eval_data, eval_targets, selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57e9c20f-bba8-4b80-a91f-2c61669a03e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_long_term_forecast = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a72de26c-9503-44e1-87ba-34803ae3dad5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_trained_model(params):\n",
    "    if params is None:\n",
    "        return\n",
    "\n",
    "    # Extract parameters\n",
    "    model_name = params['model_name']\n",
    "    hidden_size = params['hidden_size']\n",
    "    num_layers = params['num_layers']\n",
    "    dropout = params['dropout']\n",
    "    num_epochs = params['num_epochs']\n",
    "    batch_size = params['batch_size']\n",
    "    learning_rate = params['learning_rate']\n",
    "    patience = params['patience']\n",
    "    mse_decay = params['mse_decay']\n",
    "\n",
    "    # Determine input size and output size\n",
    "    input_size = {\n",
    "        # 'long': len(important_features_for_6h)+6,\n",
    "        'long': len(important_features_for_long)+6,\n",
    "        'short': len(important_features_for_short)+6,\n",
    "        'single': len(important_features_for_short)+6\n",
    "    }\n",
    "    output_size = {\n",
    "        'long': dataset_params['long_term_pred_length'],\n",
    "        'short': dataset_params['short_term_pred_length'],\n",
    "        'single': dataset_params['prediction_length']\n",
    "    }\n",
    "\n",
    "    if mse_decay:\n",
    "        mse_alpha = 0.3\n",
    "        mse_beta = 1.0\n",
    "\n",
    "    else:\n",
    "        mse_alpha = 1.0\n",
    "        mse_beta = 1.0\n",
    "\n",
    "    # Model 생성 \n",
    "    model = create_model(\n",
    "        model_name=model_name,\n",
    "        input_size=input_size,\n",
    "        hidden_size=hidden_size,\n",
    "        num_layers=num_layers,\n",
    "        output_size=output_size,\n",
    "        dropout=dropout, \n",
    "        long_term_length=dataset_params['long_term_length'], \n",
    "        short_term_length=dataset_params['short_term_length']\n",
    "    ) \n",
    "\n",
    "    if 'LS_CNNLSTM' in model_name:\n",
    "        model_path = './trained_models/important_features_{}_{}_{}_long_{}_short_{}_{}_{}_{}_alpha_{}_beta_{}.pth'.format(\n",
    "            input_size['long'], input_size['short'],\n",
    "            model_name, dataset_params['long_term_length'], dataset_params['short_term_length'],\n",
    "            dataset_params['long_term_pred_length'], hidden_size, num_layers, mse_alpha, mse_beta\n",
    "        )\n",
    "    else:\n",
    "        model_path = './trained_models/important_features_{}_{}_{}.pth'.format(\n",
    "            model_name, dataset_params['sequence_length'], dataset_params['prediction_length']\n",
    "        )\n",
    "        \n",
    "    print(\"Model path:\", model_path)\n",
    "\n",
    "    # Load pre-trained model or train a new one\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"Loading the pre-trained {model_name} model...\")\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        model.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "    else:\n",
    "        print(f\"{model_name} model not found. Training a new model...\")\n",
    "        if 'LS_CNNLSTM' in model_name:\n",
    "            train_for_long_term_forecast(\n",
    "                model=model,\n",
    "                model_name=model_name,\n",
    "                train_data=train_data,\n",
    "                train_targets=train_targets,\n",
    "                eval_data=eval_data,\n",
    "                eval_targets=eval_targets,\n",
    "                model_path=model_path,\n",
    "                num_epochs=num_epochs,\n",
    "                batch_size=batch_size,\n",
    "                learning_rate=learning_rate,\n",
    "                patience=patience,\n",
    "                oversample_eval=True, \n",
    "                alpha=mse_alpha, \n",
    "                beta=mse_beta\n",
    "            )\n",
    "        else:\n",
    "            train_for_short_term_forecast(\n",
    "                model=model,\n",
    "                model_name=model_name,\n",
    "                train_sequences=train_data,\n",
    "                train_targets=train_targets,\n",
    "                eval_sequences=eval_data,\n",
    "                eval_targets=eval_targets,\n",
    "                model_path=model_path,\n",
    "                num_epochs=num_epochs,\n",
    "                batch_size=batch_size,\n",
    "                learning_rate=learning_rate,\n",
    "                patience=patience\n",
    "            )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "add36674-2fd5-4f90-9dad-a6a2c7da561b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path: ./trained_models/important_features_11_11_LS_CNNLSTM_long_2160_short_720_256_256_3_alpha_1.0_beta_1.0.pth\n",
      "Loading the pre-trained LS_CNNLSTM model...\n",
      "Evaluating the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20448/4037395042.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score: 0.8371\n",
      "Adjusted R²: 0.8368\n",
      "SMAPE: 33.34\n",
      "MASE: 0.5897\n",
      "Model path: ./trained_models/important_features_11_11_LS_CNNLSTM_long_2160_short_720_256_256_3_alpha_0.3_beta_1.0.pth\n",
      "Loading the pre-trained LS_CNNLSTM model...\n",
      "Evaluating the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20448/4037395042.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score: 0.8720\n",
      "Adjusted R²: 0.8717\n",
      "SMAPE: 31.66\n",
      "MASE: 0.5269\n",
      "Model path: ./trained_models/important_features_11_11_LS_CNNLSTM_long_2160_short_720_256_512_3_alpha_0.3_beta_1.0.pth\n",
      "Loading the pre-trained LS_CNNLSTM model...\n",
      "Evaluating the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20448/4037395042.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score: 0.9034\n",
      "Adjusted R²: 0.9032\n",
      "SMAPE: 28.62\n",
      "MASE: 0.4621\n",
      "Model path: ./trained_models/important_features_11_11_LS_CNNLSTM_long_2160_short_720_256_512_3_alpha_1.0_beta_1.0.pth\n",
      "Loading the pre-trained LS_CNNLSTM model...\n",
      "Evaluating the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20448/4037395042.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score: 0.8045\n",
      "Adjusted R²: 0.8042\n",
      "SMAPE: 93.90\n",
      "MASE: 0.6621\n",
      "Model path: ./trained_models/important_features_11_11_LS_CNNLSTM_Att_long_2160_short_720_256_256_3_alpha_1.0_beta_1.0.pth\n",
      "Loading the pre-trained LS_CNNLSTM_Att model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20448/4037395042.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model...\n",
      "R² Score: 0.7809\n",
      "Adjusted R²: 0.7805\n",
      "SMAPE: 36.70\n",
      "MASE: 0.6828\n",
      "Model path: ./trained_models/important_features_11_11_LS_CNNLSTM_Att_long_2160_short_720_256_256_3_alpha_0.3_beta_1.0.pth\n",
      "Loading the pre-trained LS_CNNLSTM_Att model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20448/4037395042.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model...\n",
      "R² Score: 0.7161\n",
      "Adjusted R²: 0.7156\n",
      "SMAPE: 40.73\n",
      "MASE: 0.7783\n",
      "Model path: ./trained_models/important_features_11_11_LS_CNNLSTM_Att_long_2160_short_720_256_512_3_alpha_0.3_beta_1.0.pth\n",
      "Loading the pre-trained LS_CNNLSTM_Att model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20448/4037395042.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model...\n",
      "R² Score: 0.7676\n",
      "Adjusted R²: 0.7671\n",
      "SMAPE: 37.42\n",
      "MASE: 0.7044\n",
      "Model path: ./trained_models/important_features_11_11_LS_CNNLSTM_Att_long_2160_short_720_256_512_3_alpha_1.0_beta_1.0.pth\n",
      "Loading the pre-trained LS_CNNLSTM_Att model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20448/4037395042.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model...\n",
      "R² Score: 0.4861\n",
      "Adjusted R²: 0.4851\n",
      "SMAPE: 133.01\n",
      "MASE: 0.8530\n"
     ]
    }
   ],
   "source": [
    "top_5_resutls = {}\n",
    "\n",
    "\n",
    "for key, important_features in important_features_dict.items():\n",
    "    important_features_for_long = []\n",
    "    important_features_for_short = []\n",
    "\n",
    "    for feature_long in important_features['Important Long-term Features']:\n",
    "        important_features_for_long.append(feature_long)\n",
    "    \n",
    "    for feature_short in important_features['Important Short-term Features']:\n",
    "        important_features_for_short.append(feature_short)\n",
    "\n",
    "    \n",
    "    train_data, train_targets, eval_data, eval_targets, selected_features = load_dataset_new_features(params=dataset_params,\n",
    "                                                                                                      is_long_term_forecast=True)\n",
    "\n",
    "    \n",
    "    # print(important_features)\n",
    "    model_name = key.split('_long')[0]\n",
    "    hidden_size = 512 if '512' in key else 256\n",
    "    mse_decay = True if '0.3' in key else False\n",
    "\n",
    "    model_params = {\n",
    "        'model_name' : model_name, \n",
    "        'hidden_size' : hidden_size,\n",
    "        'num_layers' : 3,  # 3\n",
    "        'dropout' : 0.3,\n",
    "        'num_epochs' : 200,\n",
    "        'batch_size' : 16,\n",
    "        'learning_rate' : 0.001,\n",
    "        'patience' : 12,\n",
    "        'mse_decay' : mse_decay\n",
    "    }\n",
    "\n",
    "\n",
    "    # build model \n",
    "    model = load_trained_model(model_params)\n",
    "    \n",
    "    print(\"Evaluating the model...\")\n",
    "    if is_long_term_forecast:\n",
    "        results = evaluate_for_long_term_forecast(\n",
    "            model=model,\n",
    "            eval_data=eval_data,\n",
    "            eval_targets=eval_targets,\n",
    "            model_name=model_params['model_name'],\n",
    "            batch_size=model_params['batch_size'], \n",
    "            oversample_eval=True \n",
    "        )\n",
    "    else:\n",
    "        results = evaluate_for_short_term_forecast(\n",
    "            model=model,\n",
    "            eval_sequences=eval_short,\n",
    "            eval_targets=eval_targets_short,\n",
    "            model_name=model_params['model_name'],\n",
    "            batch_size=model_params['batch_size']\n",
    "        )\n",
    "\n",
    "    key = '{}_{}_{}'.format(model_name, hidden_size, mse_decay)\n",
    "    top_5_resutls[key] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca7c2338-6c21-4d84-9a46-8bb08426edb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LS_CNNLSTM_256_False': {'R2 Short': 0.8371367454528809,\n",
       "  'Adjusted R2': 0.8368351975989812,\n",
       "  'SMAPE Short': np.float32(33.336685),\n",
       "  'MASE Short': np.float32(0.5897087)},\n",
       " 'LS_CNNLSTM_256_True': {'R2 Short': 0.8719820380210876,\n",
       "  'Adjusted R2': 0.8717450076252338,\n",
       "  'SMAPE Short': np.float32(31.65939),\n",
       "  'MASE Short': np.float32(0.5268928)},\n",
       " 'LS_CNNLSTM_512_True': {'R2 Short': 0.9033562541007996,\n",
       "  'Adjusted R2': 0.9031773143255275,\n",
       "  'SMAPE Short': np.float32(28.621027),\n",
       "  'MASE Short': np.float32(0.4620556)},\n",
       " 'LS_CNNLSTM_512_False': {'R2 Short': 0.8045212030410767,\n",
       "  'Adjusted R2': 0.8041592662010585,\n",
       "  'SMAPE Short': np.float32(93.898224),\n",
       "  'MASE Short': np.float32(0.66205746)},\n",
       " 'LS_CNNLSTM_Att_256_False': {'R2 Short': 0.7808800935745239,\n",
       "  'Adjusted R2': 0.7804743842712618,\n",
       "  'SMAPE Short': np.float32(36.70067),\n",
       "  'MASE Short': np.float32(0.68280476)},\n",
       " 'LS_CNNLSTM_Att_256_True': {'R2 Short': 0.7161310315132141,\n",
       "  'Adjusted R2': 0.7156054367222101,\n",
       "  'SMAPE Short': np.float32(40.73091),\n",
       "  'MASE Short': np.float32(0.77825147)},\n",
       " 'LS_CNNLSTM_Att_512_True': {'R2 Short': 0.7675671577453613,\n",
       "  'Adjusted R2': 0.767136799006967,\n",
       "  'SMAPE Short': np.float32(37.423565),\n",
       "  'MASE Short': np.float32(0.7044369)},\n",
       " 'LS_CNNLSTM_Att_512_False': {'R2 Short': 0.4860598146915436,\n",
       "  'Adjusted R2': 0.4851082338064412,\n",
       "  'SMAPE Short': np.float32(133.00502),\n",
       "  'MASE Short': np.float32(0.8529608)}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_resutls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeda46f-50b1-4654-be10-c430642fa071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4fc7ccef-7d10-4233-a158-323143a95aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['LS_CNNLSTM_256_True', 'LS_CNNLSTM_256_False', 'LS_CNNLSTM_512_True', 'LS_CNNLSTM_512_False', 'LS_CNNLSTM_Att_256_True', 'LS_CNNLSTM_Att_256_False', 'LS_CNNLSTM_Att_512_True', 'LS_CNNLSTM_Att_512_False'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_results.keys() / top_5_resutls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e49941d7-ff6f-4068-81fe-3e705b10bbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model (w/ Params) \t\t\t\t R2(↑) \t\t\t Adj_R2(↑) \t\t SMAPE(↓) \t\t MASE(↓)\n",
      "LS_CNNLSTM_256_True\t\t\t\t 0.860\t\t\t 0.859\t\t\t 33.178\t\t\t 0.553\t\t\t\n",
      "LS_CNNLSTM_256_True(top 5)\t\t\t 0.872\t\t\t 0.872\t\t\t 31.659\t\t\t 0.527\t\t\t\n",
      "\n",
      "LS_CNNLSTM_256_False\t\t\t\t 0.849\t\t\t 0.848\t\t\t 33.692\t\t\t 0.572\t\t\t\n",
      "LS_CNNLSTM_256_False(top 5)\t\t\t 0.837\t\t\t 0.837\t\t\t 33.337\t\t\t 0.590\t\t\t\n",
      "\n",
      "LS_CNNLSTM_512_True\t\t\t\t 0.833\t\t\t 0.833\t\t\t 33.992\t\t\t 0.596\t\t\t\n",
      "LS_CNNLSTM_512_True(top 5)\t\t\t 0.903\t\t\t 0.903\t\t\t 28.621\t\t\t 0.462\t\t\t\n",
      "\n",
      "LS_CNNLSTM_512_False\t\t\t\t 0.835\t\t\t 0.835\t\t\t 34.892\t\t\t 0.596\t\t\t\n",
      "LS_CNNLSTM_512_False(top 5)\t\t\t 0.805\t\t\t 0.804\t\t\t 93.898\t\t\t 0.662\t\t\t\n",
      "\n",
      "LS_CNNLSTM_Att_256_True\t\t\t\t 0.726\t\t\t 0.726\t\t\t 39.989\t\t\t 0.769\t\t\t\n",
      "LS_CNNLSTM_Att_256_True(top 5)\t\t\t 0.716\t\t\t 0.716\t\t\t 40.731\t\t\t 0.778\t\t\t\n",
      "\n",
      "LS_CNNLSTM_Att_256_False\t\t\t\t 0.709\t\t\t 0.708\t\t\t 41.084\t\t\t 0.792\t\t\t\n",
      "LS_CNNLSTM_Att_256_False(top 5)\t\t\t 0.781\t\t\t 0.780\t\t\t 36.701\t\t\t 0.683\t\t\t\n",
      "\n",
      "LS_CNNLSTM_Att_512_True\t\t\t\t 0.778\t\t\t 0.778\t\t\t 38.919\t\t\t 0.697\t\t\t\n",
      "LS_CNNLSTM_Att_512_True(top 5)\t\t\t 0.768\t\t\t 0.767\t\t\t 37.424\t\t\t 0.704\t\t\t\n",
      "\n",
      "LS_CNNLSTM_Att_512_False\t\t\t\t 0.815\t\t\t 0.814\t\t\t 37.506\t\t\t 0.638\t\t\t\n",
      "LS_CNNLSTM_Att_512_False(top 5)\t\t\t 0.486\t\t\t 0.485\t\t\t 133.005\t\t\t 0.853\t\t\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "first_row = 'Model (w/ Params) \\t\\t\\t\\t R2(↑) \\t\\t\\t Adj_R2(↑) \\t\\t SMAPE(↓) \\t\\t MASE(↓)'\n",
    "print(first_row)\n",
    "\n",
    "for model_type, performance in original_results.items():\n",
    "    print_str = model_type + '\\t\\t\\t\\t'\n",
    "    for eval_metric, measurement in performance.items():\n",
    "        print_str += '{: .3f}'.format(measurement) + '\\t\\t\\t'\n",
    "    print_str += '\\n'\n",
    "\n",
    "    print_str += model_type + '(top 5)' + '\\t\\t\\t'\n",
    "    top_5_performance = top_5_resutls[model_type]\n",
    "    for eval_metric, measurement in top_5_performance.items():\n",
    "        print_str += '{: .3f}'.format(measurement) + '\\t\\t\\t'\n",
    "    print_str += '\\n'\n",
    "\n",
    "    print(print_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7dd8655c-f5e9-44c8-ad68-1881226e25a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LS_CNNLSTM_256_False': {'R2 Short': 0.8371367454528809,\n",
       "  'Adjusted R2': 0.8368351975989812,\n",
       "  'SMAPE Short': np.float32(33.336685),\n",
       "  'MASE Short': np.float32(0.5897087)},\n",
       " 'LS_CNNLSTM_256_True': {'R2 Short': 0.8719820380210876,\n",
       "  'Adjusted R2': 0.8717450076252338,\n",
       "  'SMAPE Short': np.float32(31.65939),\n",
       "  'MASE Short': np.float32(0.5268928)},\n",
       " 'LS_CNNLSTM_512_True': {'R2 Short': 0.9033562541007996,\n",
       "  'Adjusted R2': 0.9031773143255275,\n",
       "  'SMAPE Short': np.float32(28.621027),\n",
       "  'MASE Short': np.float32(0.4620556)},\n",
       " 'LS_CNNLSTM_512_False': {'R2 Short': 0.8045212030410767,\n",
       "  'Adjusted R2': 0.8041592662010585,\n",
       "  'SMAPE Short': np.float32(93.898224),\n",
       "  'MASE Short': np.float32(0.66205746)},\n",
       " 'LS_CNNLSTM_Att_256_False': {'R2 Short': 0.7808800935745239,\n",
       "  'Adjusted R2': 0.7804743842712618,\n",
       "  'SMAPE Short': np.float32(36.70067),\n",
       "  'MASE Short': np.float32(0.68280476)},\n",
       " 'LS_CNNLSTM_Att_256_True': {'R2 Short': 0.7161310315132141,\n",
       "  'Adjusted R2': 0.7156054367222101,\n",
       "  'SMAPE Short': np.float32(40.73091),\n",
       "  'MASE Short': np.float32(0.77825147)},\n",
       " 'LS_CNNLSTM_Att_512_True': {'R2 Short': 0.7675671577453613,\n",
       "  'Adjusted R2': 0.767136799006967,\n",
       "  'SMAPE Short': np.float32(37.423565),\n",
       "  'MASE Short': np.float32(0.7044369)},\n",
       " 'LS_CNNLSTM_Att_512_False': {'R2 Short': 0.4860598146915436,\n",
       "  'Adjusted R2': 0.4851082338064412,\n",
       "  'SMAPE Short': np.float32(133.00502),\n",
       "  'MASE Short': np.float32(0.8529608)}}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d55831-b100-47da-b577-0e6ffbe4abbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
