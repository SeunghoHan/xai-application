{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d97680c-e489-4cad-b8f3-37e2d0978e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random \n",
    "import pickle\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sns\n",
    "# from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "\n",
    "from data.data_loader import EPCDataset, PowerWeatherDatasetWithSeason, PowerWeatherDataset, SingleTermDataset, MultiTermDataset\n",
    "from models.lstm import LSTMModel\n",
    "from models.lstm_attention import LSTMWithAttention, BiLSTMWithAttention\n",
    "from models.gru import GRUModel\n",
    "from models.utils import create_model, train_and_evaluate, load_model, evaluate_model, evaluate_ensemble\n",
    "\n",
    "from explainers.utils import get_explainer\n",
    "# from explainers.lime import LimeExplainer\n",
    "# from explainers.shap import ShapExplainer\n",
    "# from explainers.attention import AttentionExplainer\n",
    "# from explainers.grad_cam import GradCAMExplainer\n",
    "# from explainers.lrp import LRPExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cef2be13-822a-4f74-b8b6-7c93cb9d9d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb495b65-33cd-4902-bbe4-8382b52b1154",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_for_1h = [\n",
    "    'Global_active_power',\n",
    "    'Global_intensity',\n",
    "    'Sub_metering_1', \n",
    "    'Sub_metering_2', \n",
    "    'Sub_metering_3', \n",
    "    'Temperature',\t\n",
    "    'Humidity',\t\n",
    "]\n",
    "\n",
    "features_for_6h = [\n",
    "    'Global_active_power',\n",
    "    'Global_intensity',\n",
    "    'Sub_metering_1', \n",
    "    'Sub_metering_2', \n",
    "    'Sub_metering_3', \n",
    "    'Temp_Min',\t'Temp_Max', 'Temp_Avg',\t'Temp_Range',\n",
    "    'Humidity_Min',\t'Humidity_Max',\t'Humidity_Avg',\t'Humidity_Range'\n",
    "]\n",
    "\n",
    "\n",
    "file_path_for_1h = 'data/final_data.csv'\n",
    "file_path_for_6h = 'data/final_data_per_6hr_with_avg_range.csv'\n",
    "\n",
    "\n",
    "long_term_length = 365 * 4\n",
    "long_term_pred_length = 256 # ?64, 128, 256\n",
    "\n",
    "short_term_length = 30 * 24 # 1시간 단위 한달 데이터\n",
    "short_term_pred_length = 7 * 24 # 하루치 데이터 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a9b48cd-1a0b-47fd-ac84-d144b481deab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-hour data sequences generated:\n",
      "Train sequences shape: torch.Size([23810, 720, 13])\n",
      "Train targets shape: torch.Size([23810, 168])\n",
      "Eval sequences shape: torch.Size([5953, 720, 13])\n",
      "Eval targets shape: torch.Size([5953, 168])\n",
      "\n",
      "Processing 6-hour data...\n",
      "6-hour data sequences generated:\n",
      "Train sequences shape: torch.Size([2713, 1460, 19])\n",
      "Train targets shape: torch.Size([2713, 256])\n",
      "Eval sequences shape: torch.Size([679, 1460, 19])\n",
      "Eval targets shape: torch.Size([679, 256])\n"
     ]
    }
   ],
   "source": [
    "dataset_1h = EPCDataset(\n",
    "    file_path=file_path_for_1h,\n",
    "    sequence_length=short_term_length,  # Use short-term length for 1-hour data\n",
    "    prediction_length=short_term_pred_length,\n",
    "    target_features=features_for_1h\n",
    ")\n",
    "\n",
    "train_short, train_targets_short, eval_short, eval_targets_short = dataset_1h.load_data()\n",
    "\n",
    "print(\"1-hour data sequences generated:\")\n",
    "print(f\"Train sequences shape: {train_short.shape}\")\n",
    "print(f\"Train targets shape: {train_targets_short.shape}\")\n",
    "print(f\"Eval sequences shape: {eval_short.shape}\")\n",
    "print(f\"Eval targets shape: {eval_targets_short.shape}\")\n",
    "\n",
    "# Generate sequences for 6-hour data\n",
    "print(\"\\nProcessing 6-hour data...\")\n",
    "dataset_6h = EPCDataset(\n",
    "    file_path=file_path_for_6h,\n",
    "    sequence_length=long_term_length,  # Use long-term length for 6-hour data\n",
    "    prediction_length=long_term_pred_length,\n",
    "    target_features=features_for_6h\n",
    ")\n",
    "\n",
    "train_long, train_targets_long, eval_long, eval_targets_long = dataset_6h.load_data()\n",
    "\n",
    "# #  1시간 1년\n",
    "# dataset_long = EPCDataset(\n",
    "#     file_path=file_path_for_1h,\n",
    "#     sequence_length=long_term_length,  # Use long-term length for 6-hour data\n",
    "#     prediction_length=long_term_pred_length,\n",
    "#     target_features=features_for_1h\n",
    "# )\n",
    "\n",
    "# train_long, train_targets_long, eval_long, eval_targets_long = dataset_long.load_data()\n",
    "\n",
    "\n",
    "print(\"6-hour data sequences generated:\")\n",
    "print(f\"Train sequences shape: {train_long.shape}\")\n",
    "print(f\"Train targets shape: {train_targets_long.shape}\")\n",
    "print(f\"Eval sequences shape: {eval_long.shape}\")\n",
    "print(f\"Eval targets shape: {eval_targets_long.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "901e96d7-6e64-40d8-bae4-d0ac97c856c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.lstm import LSTMModel\n",
    "from models.gru import GRUModel\n",
    "from models.cnnlstm import CNNLSTMModel\n",
    "from models.lstm_attention import AttentionLSTMModel, LSTMWithAttention\n",
    "from models.ls_cnnlstm import LongShortCNNLSTM\n",
    "from models.ls_cnnlstm_attention import LongShortCNNLSTMWithAttention\n",
    "\n",
    "def create_model2(model_name, input_size, hidden_size, num_layers, output_size, dropout=0.2, long_term_length=None, short_term_length=None):\n",
    "    ls_key = 'short'\n",
    "    \n",
    "    if model_name == 'GRU':\n",
    "        return GRUModel(input_size[ls_key], hidden_size, num_layers, output_size[ls_key], dropout)\n",
    "    elif model_name == 'LSTM':\n",
    "        return LSTMModel(input_size[ls_key], hidden_size, num_layers, output_size[ls_key], dropout)\n",
    "    elif model_name == 'LSTM-Att':\n",
    "        return LSTMWithAttention(input_size[ls_key], hidden_size, num_layers, output_size[ls_key], dropout)\n",
    "    elif model_name == 'CNNLSTM':\n",
    "        return CNNLSTMModel(input_size[ls_key], hidden_size, num_layers, output_size[ls_key], dropout)\n",
    "    elif model_name == 'LS_CNNLSTM': \n",
    "        return LongShortCNNLSTM(\n",
    "            long_input_size=input_size['long'],\n",
    "            short_input_size=input_size['short'],\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            long_output_size=output_size['long'],\n",
    "            short_output_size=output_size['short'],\n",
    "            long_term_length=long_term_length,\n",
    "            short_term_length=short_term_length,\n",
    "            dropout=dropout\n",
    "        )\n",
    "    elif model_name == 'LS_CNNLSTM_Att': \n",
    "        return LongShortCNNLSTMWithAttention(\n",
    "            input_dim_long=input_size['long'],\n",
    "            input_dim_short=input_size['short'],\n",
    "            hidden_dim=hidden_size,\n",
    "            long_output_dim=output_size['long'],\n",
    "            output_dim=output_size['short'], \n",
    "            seq_len_long=long_term_length, \n",
    "            seq_len_short=short_term_length)\n",
    "    else:\n",
    "        raise ValueError(f\"Model {model_name} is not recognized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0133c117-5db7-4609-9c5c-74934dd45f7e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class LS_Loss(nn.Module):\n",
    "    def __init__(self, alpha=1.0, beta=0.3, gamma=0.0):\n",
    "        super(LS_Loss, self).__init__()\n",
    "        self.alpha = alpha  # Weight for Short-term Loss\n",
    "        self.beta = beta    # Weight for Long-term Loss\n",
    "        self.gamma = gamma  # Weight for Cross-Modality Consistency Loss\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, output_long, target_long, output_short, target_short):\n",
    "        # Short-term Loss\n",
    "        loss_short = self.mse_loss(output_short, target_short)\n",
    "\n",
    "        # Long-term Loss\n",
    "        loss_long = self.mse_loss(output_long, target_long)\n",
    "\n",
    "        # Optional: Cross-Modality Consistency Loss\n",
    "        consistency_loss = 0.0\n",
    "        if self.gamma > 0:\n",
    "            long_mean = torch.mean(output_long, dim=1, keepdim=True)\n",
    "            short_mean = torch.mean(output_short, dim=1, keepdim=True)\n",
    "            consistency_loss = torch.mean((long_mean - short_mean) ** 2)\n",
    "\n",
    "        # Combined Loss\n",
    "        total_loss = self.alpha * loss_short + self.beta * loss_long + self.gamma * consistency_loss\n",
    "        return total_loss\n",
    "\n",
    "class SimpleMSELoss(nn.Module):\n",
    "    def __init__(self, alpha=1.0, beta=0.1):\n",
    "        super(SimpleMSELoss, self).__init__()\n",
    "        self.alpha = alpha  # Weight for Short-term Loss\n",
    "        self.beta = beta    # Weight for Long-term Loss\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, output_long, target_long, output_short, target_short):\n",
    "        # Short-term Loss\n",
    "        loss_short = self.mse_loss(output_short, target_short)\n",
    "\n",
    "        # Long-term Loss\n",
    "        loss_long = self.mse_loss(output_long, target_long)\n",
    "\n",
    "        # Combined Loss\n",
    "        total_loss = self.alpha * loss_short + self.beta * loss_long\n",
    "        return total_loss\n",
    "\n",
    "def oversample_data(long_data, short_data, long_targets, short_targets):\n",
    "    \"\"\"\n",
    "    Oversample short-term data to match the size of long-term data.\n",
    "    \"\"\"\n",
    "    # Check the smaller dataset\n",
    "    if len(short_data) < len(long_data):\n",
    "        # Calculate the oversample factor and residual\n",
    "        oversample_factor = len(long_data) // len(short_data)\n",
    "        residual_samples = len(long_data) % len(short_data)\n",
    "\n",
    "        # Oversample short data\n",
    "        short_data = torch.cat([short_data] * oversample_factor + [short_data[:residual_samples]], dim=0)\n",
    "        short_targets = torch.cat([short_targets] * oversample_factor + [short_targets[:residual_samples]], dim=0)\n",
    "    elif len(long_data) < len(short_data):\n",
    "        # Calculate the oversample factor and residual for long data\n",
    "        oversample_factor = len(short_data) // len(long_data)\n",
    "        residual_samples = len(short_data) % len(long_data)\n",
    "\n",
    "        # Oversample long data\n",
    "        long_data = torch.cat([long_data] * oversample_factor + [long_data[:residual_samples]], dim=0)\n",
    "        long_targets = torch.cat([long_targets] * oversample_factor + [long_targets[:residual_samples]], dim=0)\n",
    "    \n",
    "    # Ensure shapes match after oversampling\n",
    "    assert len(long_data) == len(short_data), \"Oversampling failed to match dataset sizes!\"\n",
    "    assert len(long_targets) == len(short_targets), \"Oversampling failed to match target sizes!\"\n",
    "\n",
    "    return long_data, short_data, long_targets, short_targets\n",
    "    \n",
    "\n",
    "def train_and_evaluate3(model, model_name, train_data, train_targets, eval_data, eval_targets, model_path, num_epochs=100, batch_size=64, learning_rate=0.001, patience=5, oversample_eval=False):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    train_long, train_short = train_data\n",
    "    train_targets_long, train_targets_short = train_targets\n",
    "\n",
    "    eval_long, eval_short = eval_data\n",
    "    eval_targets_long, eval_targets_short = eval_targets\n",
    "\n",
    "    # Oversample training data\n",
    "    train_long, train_short, train_targets_long, train_targets_short = oversample_data(\n",
    "        train_long, train_short, train_targets_long, train_targets_short\n",
    "    )\n",
    "    print(f\"After Oversampling:\")\n",
    "    print(f\"Train Long-term shape: {train_long.shape}\")\n",
    "    print(f\"Train Short-term shape: {train_short.shape}\")\n",
    "\n",
    "    # Optionally oversample evaluation data\n",
    "    if oversample_eval:\n",
    "        eval_long, eval_short, eval_targets_long, eval_targets_short = oversample_data(\n",
    "            eval_long, eval_short, eval_targets_long, eval_targets_short\n",
    "        )\n",
    "\n",
    "    # Adjust evaluation data sizes if oversample is not applied\n",
    "    if not oversample_eval:\n",
    "        min_eval_size = min(len(eval_long), len(eval_short))\n",
    "        eval_long = eval_long[:min_eval_size]\n",
    "        eval_short = eval_short[:min_eval_size]\n",
    "        eval_targets_long = eval_targets_long[:min_eval_size]\n",
    "        eval_targets_short = eval_targets_short[:min_eval_size]\n",
    "\n",
    "    # DataLoaders\n",
    "    train_dataset = torch.utils.data.TensorDataset(train_long, train_short, train_targets_long, train_targets_short)\n",
    "    eval_dataset = torch.utils.data.TensorDataset(eval_long, eval_short, eval_targets_long, eval_targets_short)\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    eval_loader = DataLoader(dataset=eval_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Loss function and optimizer\n",
    "    # criterion = nn.MSELoss()\n",
    "    criterion = SimpleMSELoss(alpha=0.3, beta=1.0)\n",
    "    # criterion = LS_Loss(alpha=1.0, beta=0.3, gamma=0.2, lambda_=0.1, eta=0.01)\n",
    "    \n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for long_batch, short_batch, target_long, target_short in train_loader:\n",
    "            long_batch, short_batch = long_batch.to(device), short_batch.to(device)\n",
    "            target_long, target_short = target_long.to(device), target_short.to(device)\n",
    "\n",
    "            if 'Att' in model_name:\n",
    "                output_long, output_short, attention_weights = model(long_batch, short_batch)\n",
    "            else:\n",
    "                output_long, output_short = model(long_batch, short_batch)\n",
    "            \n",
    "            # loss = criterion(output_long, target_long) + criterion(output_short, target_short)\n",
    "            loss = criterion(output_long, target_long, output_short, target_short)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        eval_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for long_batch, short_batch, target_long, target_short in eval_loader:\n",
    "                long_batch, short_batch = long_batch.to(device), short_batch.to(device)\n",
    "                target_long, target_short = target_long.to(device), target_short.to(device)\n",
    "                    \n",
    "                if 'Att' in model_name:\n",
    "                    output_long, output_short, attention_weights = model(long_batch, short_batch)\n",
    "                else:\n",
    "                    output_long, output_short = model(long_batch, short_batch)\n",
    "                \n",
    "                # loss = criterion(output_long, target_long) + criterion(output_short, target_short)\n",
    "                loss = criterion(output_long, target_long, output_short, target_short)\n",
    "                \n",
    "                eval_loss += loss.item()\n",
    "\n",
    "        eval_loss /= len(eval_loader)\n",
    "        scheduler.step(eval_loss)\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {eval_loss:.4f}\")\n",
    "\n",
    "        criterion.alpha = min(1.0, criterion.alpha + 0.05)  # Increase alpha\n",
    "        criterion.beta = max(0.1, criterion.beta - 0.05)   # Decrease beta\n",
    "        \n",
    "        # Early stopping\n",
    "        if eval_loss < best_val_loss:\n",
    "            best_val_loss = eval_loss\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(f\"Validation loss improved. Model saved at epoch {epoch+1}\")\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95fd44b7-6e88-4b07-b406-0bb8e6846429",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate2(model, model_name, train_sequences, train_targets, \n",
    "                       eval_sequences, eval_targets, model_path, num_epochs=100, \n",
    "                       batch_size=64, learning_rate=0.001, patience=5):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    # Data loader\n",
    "    train_dataset = torch.utils.data.TensorDataset(torch.tensor(train_sequences, dtype=torch.float32), torch.tensor(train_targets, dtype=torch.float32))\n",
    "    eval_dataset = torch.utils.data.TensorDataset(torch.tensor(eval_sequences, dtype=torch.float32), torch.tensor(eval_targets, dtype=torch.float32))\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    eval_loader = torch.utils.data.DataLoader(dataset=eval_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) #, weight_decay=1e-5)\n",
    "\n",
    "    best_val_loss = np.inf\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # tqdm을 사용하여 학습 진행도 표시\n",
    "        with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "            for sequences_batch, targets_batch in tepoch:\n",
    "                tepoch.set_description(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "                \n",
    "                # Move batch to GPU\n",
    "                sequences_batch, targets_batch = sequences_batch.to(device), targets_batch.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                if 'Att' in model_name:\n",
    "                    outputs, _ = model(sequences_batch) \n",
    "                else:\n",
    "                    outputs = model(sequences_batch)\n",
    "\n",
    "                loss = criterion(outputs.squeeze(), targets_batch)\n",
    "\n",
    "                # Backward pass and optimization\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # 현재 배치 손실을 누적\n",
    "                running_loss += loss.item()\n",
    "                tepoch.set_postfix(loss=loss.item())\n",
    "\n",
    "        # Epoch 단위로 평균 손실 계산\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "\n",
    "        # Evaluation on the validation set\n",
    "        model.eval()\n",
    "        eval_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for sequences_batch, targets_batch in eval_loader:\n",
    "                # Move batch to GPU\n",
    "                sequences_batch, targets_batch = sequences_batch.to(device), targets_batch.to(device)\n",
    "\n",
    "                if 'Att' in model_name:\n",
    "                    val_outputs, _ = model(sequences_batch) \n",
    "                else:\n",
    "                    val_outputs = model(sequences_batch)\n",
    "                loss = criterion(val_outputs.squeeze(), targets_batch)\n",
    "                eval_loss += loss.item()\n",
    "\n",
    "        eval_loss /= len(eval_loader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {eval_loss:.7f}')\n",
    "\n",
    "        # Check if the validation loss improved\n",
    "        if eval_loss < best_val_loss:\n",
    "            best_val_loss = eval_loss\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(f\"Validation loss improved. Model saved at epoch {epoch+1}\")\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        # Early stopping\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping applied at epoch {epoch+1}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fcd92c0-32c2-4965-a5d4-9883093c4094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_model(params=None):\n",
    "    if params is None:\n",
    "        return\n",
    "\n",
    "    # Extract parameters\n",
    "    model_name = params['model_name']\n",
    "    hidden_size = params['hidden_size']\n",
    "    num_layers = params['num_layers']\n",
    "    dropout = params['dropout']\n",
    "    num_epochs = params['num_epochs']\n",
    "    batch_size = params['batch_size']\n",
    "    learning_rate = params['learning_rate']\n",
    "    patience = params['patience']\n",
    "\n",
    "    # Determine input size and output size\n",
    "    input_size = {\n",
    "        'long': len(features_for_6h)+6,\n",
    "        'short': len(features_for_1h)+6\n",
    "    }\n",
    "    output_size = {\n",
    "        'long': long_term_pred_length,\n",
    "        'short': short_term_pred_length\n",
    "    }\n",
    "\n",
    "    # Model 생성 \n",
    "    model = create_model2(\n",
    "        model_name=model_name,\n",
    "        input_size=input_size,\n",
    "        hidden_size=hidden_size,\n",
    "        num_layers=num_layers,\n",
    "        output_size=output_size,\n",
    "        dropout=dropout, \n",
    "        long_term_length=long_term_length, \n",
    "        short_term_length=short_term_length\n",
    "    )\n",
    "\n",
    "    if 'LS_CNNLSTM' in model_name:\n",
    "        model_path = './trained_models/{}_long_{}_short_{}_{}_{}_{}_ab.pth'.format(\n",
    "            model_name, long_term_length, short_term_length, long_term_pred_length, hidden_size, num_layers\n",
    "        )\n",
    "        print(\"Model path:\", model_path)\n",
    "    else:\n",
    "        model_path = './trained_models/{}_{}_{}.pth'.format(\n",
    "            model_name, short_term_length, short_term_pred_length\n",
    "        )\n",
    "        print(\"Model path:\", model_path)\n",
    "        \n",
    "\n",
    "    # Load pre-trained model or train a new one\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"Loading the pre-trained {model_name} model...\")\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        model.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "    else:\n",
    "        print(f\"{model_name} model not found. Training a new model...\")\n",
    "        if 'LS_CNNLSTM' in model_name:\n",
    "            train_and_evaluate3(\n",
    "                model=model,\n",
    "                model_name=model_name,\n",
    "                train_data=(train_long, train_short),\n",
    "                train_targets=(train_targets_long, train_targets_short),\n",
    "                eval_data=(eval_long, eval_short),\n",
    "                eval_targets=(eval_targets_long, eval_targets_short),\n",
    "                model_path=model_path,\n",
    "                num_epochs=num_epochs,\n",
    "                batch_size=batch_size,\n",
    "                learning_rate=learning_rate,\n",
    "                patience=patience,\n",
    "                oversample_eval=True\n",
    "            )\n",
    "        else:\n",
    "            train_and_evaluate2(\n",
    "                model=model,\n",
    "                model_name=model_name,\n",
    "                train_sequences=train_short,\n",
    "                train_targets=train_targets_short,\n",
    "                eval_sequences=eval_short,\n",
    "                eval_targets=eval_targets_short,\n",
    "                model_path=model_path,\n",
    "                num_epochs=num_epochs,\n",
    "                batch_size=batch_size,\n",
    "                learning_rate=learning_rate,\n",
    "                patience=patience\n",
    "            )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21cbff9e-c5de-4399-a854-0e53d7c73f5e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def smape(y_true, y_pred):\n",
    "    numerator = np.abs(y_true - y_pred)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    smape = np.mean(numerator / denominator) * 100\n",
    "    return smape\n",
    "\n",
    "# MASE 정의\n",
    "def mase(y_true, y_pred, naive_forecast=None):\n",
    "    mae_pred = np.mean(np.abs(y_true - y_pred))\n",
    "    if naive_forecast is None:\n",
    "        naive_forecast = np.roll(y_true, shift=1)\n",
    "        naive_forecast[0] = y_true[0]  # Shift로 발생하는 문제 해결\n",
    "    mae_naive = np.mean(np.abs(y_true - naive_forecast))\n",
    "    mase = mae_pred / mae_naive\n",
    "    return mase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce3e48a1-4e44-4024-b39f-60f3d4541ea9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model2(model, eval_sequences, eval_targets, model_name=\"\", batch_size=64):\n",
    "    \"\"\"\n",
    "    Evaluate a given model with R², SMAPE, and MASE.\n",
    "    \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    eval_dataset = torch.utils.data.TensorDataset(torch.tensor(eval_sequences, dtype=torch.float32),\n",
    "                                                  torch.tensor(eval_targets, dtype=torch.float32))\n",
    "    eval_loader = torch.utils.data.DataLoader(dataset=eval_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    all_outputs = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sequences_batch, targets_batch in eval_loader:\n",
    "            sequences_batch, targets_batch = sequences_batch.to(device), targets_batch.to(device)\n",
    "            \n",
    "            if 'Att' in model_name:\n",
    "                outputs, _ = model(sequences_batch)\n",
    "            else:\n",
    "                outputs = model(sequences_batch)\n",
    "\n",
    "            # 필요에 따라 squeeze() 적용\n",
    "            if outputs.shape[-1] == 1:\n",
    "                outputs = outputs.squeeze(-1)\n",
    "\n",
    "            all_outputs.append(outputs.cpu().numpy())\n",
    "            all_targets.append(targets_batch.cpu().numpy())\n",
    "\n",
    "    all_outputs = np.concatenate(all_outputs, axis=0)\n",
    "    all_targets = np.concatenate(all_targets, axis=0)\n",
    "\n",
    "    # Metrics calculation\n",
    "    r2 = r2_score(all_targets, all_outputs)\n",
    "    n = len(all_targets)\n",
    "    k = eval_data[0].shape[-1] if is_multi_input else eval_data.shape[-1]\n",
    "    adjusted_r2 = 1 - ((1 - r2) * (n - 1)) / (n - k - 1)\n",
    "    smape_score = smape(all_targets, all_outputs)\n",
    "    mase_score = mase(all_targets, all_outputs)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"R² Score: {r2:.4f}\")\n",
    "    print(f\"Adjusted R²: {adjusted_r2:.4f}\")\n",
    "    print(f\"SMAPE: {smape_score:.2f}\")\n",
    "    print(f\"MASE: {mase_score:.4f}\")\n",
    "\n",
    "    return {\"R2\": r2, \"Adjusted R2\": adjusted_r2, \"SMAPE\": smape_score, \"MASE\": mase_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0944493a-2807-4bf1-a9e2-0102af186e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model3(model, eval_data, eval_targets, model_name=\"\", \n",
    "                    batch_size=64, oversample_eval=False):\n",
    "    \"\"\"\n",
    "    Evaluate the model using R², SMAPE, and MASE metrics.\n",
    "    \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    eval_long, eval_short = eval_data\n",
    "    eval_targets_long, eval_targets_short = eval_targets\n",
    "\n",
    "    # Optionally oversample evaluation data\n",
    "    if oversample_eval:\n",
    "        eval_long, eval_short, eval_targets_long, eval_targets_short = oversample_data(\n",
    "            eval_long, eval_short, eval_targets_long, eval_targets_short\n",
    "        )\n",
    "\n",
    "    # Adjust evaluation data sizes if oversample is not applied\n",
    "    if not oversample_eval:\n",
    "        min_eval_size = min(len(eval_long), len(eval_short))\n",
    "        eval_long = eval_long[:min_eval_size]\n",
    "        eval_short = eval_short[:min_eval_size]\n",
    "        eval_targets_long = eval_targets_long[:min_eval_size]\n",
    "        eval_targets_short = eval_targets_short[:min_eval_size]\n",
    "\n",
    "    eval_dataset =  torch.utils.data.TensorDataset(eval_long, eval_short, eval_targets_long, eval_targets_short)\n",
    "    eval_loader = DataLoader(dataset=eval_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    all_outputs_long = []\n",
    "    all_outputs_short = []\n",
    "    all_targets_long = []\n",
    "    all_targets_short = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for long_batch, short_batch, long_target, short_target in eval_loader:\n",
    "            long_batch, short_batch = long_batch.to(device), short_batch.to(device)\n",
    "            long_target, short_target = long_target.to(device), short_target.to(device)\n",
    "\n",
    "            if 'Att' in model_name:\n",
    "                output_long, output_short, attention_weights = model(long_batch, short_batch)\n",
    "            else:\n",
    "                output_long, output_short = model(long_batch, short_batch)\n",
    "\n",
    "            all_outputs_long.append(output_long.cpu().numpy())\n",
    "            all_outputs_short.append(output_short.cpu().numpy())\n",
    "            all_targets_long.append(long_target.cpu().numpy())\n",
    "            all_targets_short.append(short_target.cpu().numpy())\n",
    "\n",
    "    all_outputs_long = np.concatenate(all_outputs_long, axis=0)\n",
    "    all_outputs_short = np.concatenate(all_outputs_short, axis=0)\n",
    "    all_targets_long = np.concatenate(all_targets_long, axis=0)\n",
    "    all_targets_short = np.concatenate(all_targets_short, axis=0)\n",
    "\n",
    "    # Metrics calculation for long-term and short-term predictions\n",
    "    r2_short = r2_score(all_targets_short, all_outputs_short)\n",
    "    n = len(all_targets_short)\n",
    "    k = eval_data[0].shape[-1]\n",
    "    adjusted_r2 = 1 - ((1 - r2_short) * (n - 1)) / (n - k - 1)\n",
    "    smape_short = smape(all_targets_short, all_outputs_short)\n",
    "    mase_short = mase(all_targets_short, all_outputs_short)\n",
    "\n",
    "\n",
    "    # Print results\n",
    "    print(f\"R² Score: {r2_short:.4f}\")\n",
    "    print(f\"Adjusted R²: {adjusted_r2:.4f}\")\n",
    "    print(f\"SMAPE: {smape_short:.2f}\")\n",
    "    print(f\"MASE: {mase_short:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        \"R2 Short\": r2_short,\n",
    "        \"Adjusted R2\": adjusted_r2,\n",
    "        \"SMAPE Short\": smape_short,\n",
    "        \"MASE Short\": mase_short\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e58a8aa1-3f90-42ab-a5ae-42f9d849c7b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path: ./trained_models/LS_CNNLSTM_long_1460_short_720_256_512_3_ab.pth\n",
      "Loading the pre-trained LS_CNNLSTM model...\n",
      "Evaluating the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_157/3271299019.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score: 0.8222\n",
      "Adjusted R²: 0.8216\n",
      "SMAPE: 34.95\n",
      "MASE: 0.6158\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'model_name' : 'LS_CNNLSTM', \n",
    "    'hidden_size' : 512, # 256\n",
    "    'num_layers' : 3,  # 3\n",
    "    'dropout' : 0.3,\n",
    "    'num_epochs' : 150,\n",
    "    'batch_size' : 16,\n",
    "    'learning_rate' : 0.001,\n",
    "    'patience' : 15,\n",
    "}\n",
    "\n",
    "# build model \n",
    "model = load_trained_model(params)\n",
    "\n",
    "print(\"Evaluating the model...\")\n",
    "\n",
    "if 'LS_CNNLSTM' in params['model_name']:\n",
    "    results = evaluate_model3(\n",
    "        model=model,\n",
    "        eval_data=(eval_long, eval_short),\n",
    "        eval_targets=(eval_targets_long, eval_targets_short),\n",
    "        model_name=params['model_name'],\n",
    "        batch_size=params['batch_size'], \n",
    "        oversample_eval=True \n",
    "    )\n",
    "else:\n",
    "    results = evaluate_model2(\n",
    "        model=model,\n",
    "        eval_sequences=eval_short,\n",
    "        eval_targets=eval_targets_short,\n",
    "        model_name=params['model_name'],\n",
    "        batch_size=params['batch_size']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2273c80-4d17-441f-91c0-07a00b44ddfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cd5c39-924e-4449-aec4-fdda423abdea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39590aa7-37ac-4c64-a4fc-a00f5535fe49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1eef66-9fc5-40a5-b5f2-5c2ef9308197",
   "metadata": {},
   "outputs": [],
   "source": [
    "LS_CNNLSTM_long_1460_short_720_256_256_3.pth\n",
    "\n",
    "R² Long: 0.5076, R² Short: 0.7703\n",
    "SMAPE Long: 38.99, SMAPE Short: 37.88\n",
    "MASE Long: 0.4550, MASE Short: 0.7009\n",
    "\n",
    "LS_CNNLSTM_long_1460_short_720_256_512_3.pth\n",
    "R² Long: 0.5237, R² Short: 0.8254\n",
    "SMAPE Long: 36.39, SMAPE Short: 34.46\n",
    "MASE Long: 0.4416, MASE Short: 0.6088\n",
    "\n",
    "LS_CNNLSTM_long_1460_short_720_256_1024_3.pth\n",
    "R² Long: 0.2760, R² Short: 0.7326\n",
    "SMAPE Long: 41.78, SMAPE Short: 39.92\n",
    "MASE Long: 0.5381, MASE Short: 0.7538\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "LS_CNNLSTM_long_1460_short_720_256_256_3_ab.pth\n",
    "R² Long: 0.5081, R² Short: 0.8329\n",
    "SMAPE Long: 38.46, SMAPE Short: 33.86\n",
    "MASE Long: 0.4528, MASE Short: 0.5994\n",
    "\n",
    "LS_CNNLSTM_long_1460_short_720_256_512_3_ab.pth\n",
    "R² Long: 0.4195, R² Short: 0.8222\n",
    "SMAPE Long: 38.95, SMAPE Short: 34.95\n",
    "MASE Long: 0.4866, MASE Short: 0.6158"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24a5b98-ed4b-42e2-abf7-a1ee0152b043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0564a70d-1882-4d2b-9bb5-3781e7399500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fe0766-27f3-4971-9779-d913c7089029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eabb01bb-d314-45ff-9993-6f20c651b0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LS_CNNLSTM_Att_long_1460_short_720_256_256_3\n",
    "256, 256, 3\n",
    "R² Long: 0.4926, R² Short: 0.6282\n",
    "SMAPE Long: 41.39, SMAPE Short: 43.75\n",
    "MASE Long: 0.4741, MASE Short: 0.8927\n",
    "\n",
    "\n",
    "LS_CNNLSTM_Att_long_1460_short_720_256_512_3\n",
    "R² Long: 0.4417, R² Short: 0.7718\n",
    "SMAPE Long: 36.16, SMAPE Short: 39.04\n",
    "MASE Long: 0.4698, MASE Short: 0.7043\n",
    "\n",
    "\n",
    "LS_CNNLSTM_Att_long_1460_short_720_256_1024_3.pth\n",
    "\n",
    "R² Long: 0.4569, R² Short: 0.7043\n",
    "SMAPE Long: 43.27, SMAPE Short: 42.62\n",
    "MASE Long: 0.4927, MASE Short: 0.7974\n",
    "\n",
    "\n",
    "##########\n",
    "\n",
    "\n",
    "LS_CNNLSTM_Att_long_1460_short_720_256_256_3_ab.pth\n",
    "R² Long: -0.0020, R² Short: 0.7264\n",
    "SMAPE Long: 56.80, SMAPE Short: 41.01\n",
    "MASE Long: 0.7358, MASE Short: 0.7686\n",
    "\n",
    "\n",
    "LS_CNNLSTM_Att_long_1460_short_720_256_512_3.pth\n",
    "R² Long: -0.0026, R² Short: 0.7574\n",
    "SMAPE Long: 56.82, SMAPE Short: 39.78\n",
    "MASE Long: 0.7354, MASE Short: 0.7247"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed731bf-de9f-4eae-be59-0d6ce47f8c61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc4dbe5-7ed2-4b17-b622-3bdea0312a01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d54519-f7f7-4cf6-9440-6f95ac476ee4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409c5781-7acd-46bf-9fd5-25ad1532cbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "LS_CNNLSTM_long_1460_short_168.pth\n",
    "\n",
    "LS_CNNLSTM (oversample_eval=True) \n",
    "- 24, 128 -> 0.52\n",
    " - 128, 256 -> 0.57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96492068-182d-4f50-87af-3de248d289e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_LS_CNNLSTM_Att_long_1460_short_168.pth\n",
    "\n",
    "LS_CNNLSTM_Att (oversample_eval=True) \n",
    "- 128\n",
    "R² Long: 0.4111, R² Short: 0.7501\n",
    "SMAPE Long: 46.69, SMAPE Short: 37.15\n",
    "MASE Long: 0.5172, MASE Short: 0.7029"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a00791-e926-475b-a9b5-0f5eb014c956",
   "metadata": {},
   "outputs": [],
   "source": [
    "LS_CNNLSTM_Att_long_1460_short_168_mse.pth\n",
    "\n",
    "LS_CNNLSTM_Att (oversample_eval=True) using mse loss \n",
    "- 256\n",
    "R² Long: 0.2416, R² Short: 0.8897\n",
    "SMAPE Long: 51.22, SMAPE Short: 27.54\n",
    "MASE Long: 0.5858, MASE Short: 0.4563"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef00383-1c3b-4b4a-9b5e-d7a8d900352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LS_CNNLSTM_Att_long_1460_short_168_mse_ab.pth\n",
    "\n",
    "LS_CNNLSTM_Att (oversample_eval=True) using mse loss + alpha/beta \n",
    " - 256\n",
    "R² Long: 0.1336, R² Short: 0.8873\n",
    "SMAPE Long: 57.46, SMAPE Short: 27.97\n",
    "MASE Long: 0.6374, MASE Short: 0.4611"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafdfbaa-cc3d-4464-99d4-53496740a43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LS_CNNLSTM_Att_long_8760_short_168.pth (365*24)\n",
    "\n",
    "LS_CNNLSTM_Att (oversample_eval=True) using mse loss \n",
    " - 256 \n",
    "R² Long: 0.5729, R² Short: 0.9021\n",
    "SMAPE Long: 48.14, SMAPE Short: 25.97\n",
    "MASE Long: 0.9698, MASE Short: 0.4236"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083db419-9587-4c68-a23f-07d329589d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fefb101-bd2f-43fe-b30c-e73f179802a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM, GUR, LSTP+Attention, CNN-LSTM \n",
    "\n",
    "Long/Short CNN-LSTM, Long/Short CNN-LSTM + attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b64ad2-b4b6-40d9-aae4-b6e151edab27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ada13b-6917-4ba2-8cdc-657dced0b092",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c8b82dd-677e-4214-819d-470eb38a76d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path: ./trained_models/LSTM_long_8760_short_168.pth\n",
      "Loading the pre-trained LSTM model...\n",
      "Evaluating the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_551697/2463606209.py:47: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n",
      "/tmp/ipykernel_551697/367026898.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eval_dataset = torch.utils.data.TensorDataset(torch.tensor(eval_sequences, dtype=torch.float32),\n",
      "/tmp/ipykernel_551697/367026898.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(eval_targets, dtype=torch.float32))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tR² Score: 0.9669\n",
      "\tSMAPE: 18.59\n",
      "\tMASE: 0.2632\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'model_name' : 'LSTM', \n",
    "    'hidden_size' : 128, # 256\n",
    "    'num_layers' : 2,  # 3\n",
    "    'dropout' : 0.3,\n",
    "    'num_epochs' : 150,\n",
    "    'batch_size' : 16,\n",
    "    'learning_rate' : 0.001,\n",
    "    'patience' : 5,\n",
    "}\n",
    "\n",
    "# build model \n",
    "model = load_trained_model(params)\n",
    "\n",
    "print(\"Evaluating the model...\")\n",
    "\n",
    "if 'LS_CNNLSTM' in params['model_name']:\n",
    "    results = evaluate_model3(\n",
    "        model=model,\n",
    "        eval_data=(eval_long, eval_short),\n",
    "        eval_targets=(eval_targets_long, eval_targets_short),\n",
    "        model_name=params['model_name'],\n",
    "        batch_size=params['batch_size'], \n",
    "        oversample_eval=True \n",
    "    )\n",
    "else:\n",
    "    results = evaluate_model2(\n",
    "        model=model,\n",
    "        eval_sequences=eval_short,\n",
    "        eval_targets=eval_targets_short,\n",
    "        model_name=params['model_name'],\n",
    "        batch_size=params['batch_size']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc6f989f-108f-4a01-a6a4-8e70dfb91915",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path: ./trained_models/GRU_long_8760_short_168.pth\n",
      "Loading the pre-trained GRU model...\n",
      "Evaluating the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_551697/2463606209.py:47: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n",
      "/tmp/ipykernel_551697/367026898.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eval_dataset = torch.utils.data.TensorDataset(torch.tensor(eval_sequences, dtype=torch.float32),\n",
      "/tmp/ipykernel_551697/367026898.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(eval_targets, dtype=torch.float32))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tR² Score: 0.9550\n",
      "\tSMAPE: 21.36\n",
      "\tMASE: 0.3107\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'model_name' : 'GRU', \n",
    "    'hidden_size' : 128, # 256\n",
    "    'num_layers' : 2,  # 3\n",
    "    'dropout' : 0.3,\n",
    "    'num_epochs' : 150,\n",
    "    'batch_size' : 16,\n",
    "    'learning_rate' : 0.001,\n",
    "    'patience' : 5,\n",
    "}\n",
    "\n",
    "# build model \n",
    "model = load_trained_model(params)\n",
    "\n",
    "print(\"Evaluating the model...\")\n",
    "\n",
    "if 'LS_CNNLSTM' in params['model_name']:\n",
    "    results = evaluate_model3(\n",
    "        model=model,\n",
    "        eval_data=(eval_long, eval_short),\n",
    "        eval_targets=(eval_targets_long, eval_targets_short),\n",
    "        model_name=params['model_name'],\n",
    "        batch_size=params['batch_size'], \n",
    "        oversample_eval=True \n",
    "    )\n",
    "else:\n",
    "    results = evaluate_model2(\n",
    "        model=model,\n",
    "        eval_sequences=eval_short,\n",
    "        eval_targets=eval_targets_short,\n",
    "        model_name=params['model_name'],\n",
    "        batch_size=params['batch_size']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "74de140b-df00-44b5-a115-18ae789ef6d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path: ./trained_models/CNNLSTM_long_8760_short_168.pth\n",
      "Loading the pre-trained CNNLSTM model...\n",
      "Evaluating the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_551697/2463606209.py:47: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n",
      "/tmp/ipykernel_551697/367026898.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  eval_dataset = torch.utils.data.TensorDataset(torch.tensor(eval_sequences, dtype=torch.float32),\n",
      "/tmp/ipykernel_551697/367026898.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(eval_targets, dtype=torch.float32))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tR² Score: 0.9830\n",
      "\tSMAPE: 13.24\n",
      "\tMASE: 0.1815\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'model_name' : 'CNNLSTM', \n",
    "    'hidden_size' : 256, # 256\n",
    "    'num_layers' : 3,  # 3\n",
    "    'dropout' : 0.3,\n",
    "    'num_epochs' : 150,\n",
    "    'batch_size' : 16,\n",
    "    'learning_rate' : 0.001,\n",
    "    'patience' : 5,\n",
    "}\n",
    "\n",
    "# build model \n",
    "model = load_trained_model(params)\n",
    "\n",
    "print(\"Evaluating the model...\")\n",
    "\n",
    "if 'LS_CNNLSTM' in params['model_name']:\n",
    "    results = evaluate_model3(\n",
    "        model=model,\n",
    "        eval_data=(eval_long, eval_short),\n",
    "        eval_targets=(eval_targets_long, eval_targets_short),\n",
    "        model_name=params['model_name'],\n",
    "        batch_size=params['batch_size'], \n",
    "        oversample_eval=True \n",
    "    )\n",
    "else:\n",
    "    results = evaluate_model2(\n",
    "        model=model,\n",
    "        eval_sequences=eval_short,\n",
    "        eval_targets=eval_targets_short,\n",
    "        model_name=params['model_name'],\n",
    "        batch_size=params['batch_size']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8318dc02-b02e-4d82-b1ba-bf9adfb5da37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
